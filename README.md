## ğŸ“Š Projeto ETL com GeraÃ§Ã£o de ConteÃºdo via IA  
**Bootcamp CiÃªncia de Dados â€“ Santander | DIO**

Este projeto foi desenvolvido por **Jonatha Briano** como atividade prÃ¡tica do **Bootcamp de CiÃªncia de Dados do Santander**, ofertado pela plataforma **DIO (Digital Innovation One)**.

O objetivo do projeto Ã© demonstrar, de forma prÃ¡tica, a implementaÃ§Ã£o de um **pipeline ETL (Extract, Transform, Load)** utilizando **Python**, **Pandas** e uma **API de InteligÃªncia Artificial (Groq)** como fonte de dados textuais.

---

## ğŸ§  VisÃ£o Geral do Projeto

O pipeline ETL desenvolvido tem como finalidade:
- Ler dados de usuÃ¡rios a partir de um arquivo CSV
- Enriquecer esses dados com mensagens personalizadas geradas por um modelo de linguagem
- Persistir os dados transformados em um novo arquivo estruturado (JSON)

O projeto simula um cenÃ¡rio real de mercado, onde dados estruturados sÃ£o combinados com dados nÃ£o estruturados gerados por IA.

---

## ğŸ”„ Pipeline ETL

### 1ï¸âƒ£ Extract (ExtraÃ§Ã£o)

A etapa de extraÃ§Ã£o consiste na leitura de dados estruturados a partir de um arquivo CSV utilizando a biblioteca **Pandas**.

- O arquivo `SDW2025.csv` contÃ©m informaÃ§Ãµes bÃ¡sicas dos usuÃ¡rios
- Os dados sÃ£o carregados em memÃ³ria e convertidos para uma lista de dicionÃ¡rios
- Para cada usuÃ¡rio, Ã© criada uma nova chave (`news`) que serÃ¡ utilizada nas prÃ³ximas etapas

ğŸ“Œ **Objetivo da etapa**: disponibilizar os dados brutos em uma estrutura manipulÃ¡vel para transformaÃ§Ã£o.

---

### 2ï¸âƒ£ Transform (TransformaÃ§Ã£o)

Na etapa de transformaÃ§Ã£o, os dados extraÃ­dos sÃ£o **enriquecidos com conteÃºdo gerado por InteligÃªncia Artificial**.

#### ğŸ”¹ Uso da API Groq
- A API Ã© utilizada como uma **fonte externa de dados**
- As mensagens geradas sÃ£o personalizadas com o nome de cada usuÃ¡rio
- O conteÃºdo Ã© limitado a 100 caracteres, conforme regra de negÃ³cio

#### ğŸ”¹ Boas prÃ¡ticas aplicadas
- Uso de variÃ¡veis de ambiente para armazenar a API Key
- Leitura da chave via `os.getenv()`
- Arquivo `.env` protegido e ignorado pelo Git

ğŸ“Œ **Importante**:  
Neste projeto, a resposta do modelo de linguagem Ã© tratada como **dado nÃ£o estruturado**, passando a integrar o fluxo de ETL.

Cada mensagem gerada Ã© adicionada ao respectivo usuÃ¡rio, enriquecendo o conjunto de dados original.

---

### 3ï¸âƒ£ Load (Carga)

Na etapa final, os dados transformados sÃ£o persistidos em um arquivo JSON:

- O arquivo final contÃ©m os dados originais do CSV
- Inclui as mensagens personalizadas geradas pela IA
- O formato JSON facilita reutilizaÃ§Ã£o, anÃ¡lises futuras ou integraÃ§Ã£o com outros sistemas

ğŸ“Œ **Resultado**:  
Um novo dataset enriquecido, pronto para consumo analÃ­tico ou aplicaÃ§Ãµes futuras.

---

## ğŸ“ Aprendizados

Com este projeto foi possÃ­vel consolidar conhecimentos sobre:
- Conceitos e implementaÃ§Ã£o de pipelines ETL
- ManipulaÃ§Ã£o de dados com Pandas
- Uso de APIs externas como fonte de dados
- Boas prÃ¡ticas de seguranÃ§a e versionamento com Git/GitHub
- AplicaÃ§Ã£o prÃ¡tica de InteligÃªncia Artificial em projetos de dados

---

## ğŸ ConsideraÃ§Ãµes Finais

Este projeto demonstra como pipelines ETL podem ir alÃ©m de bases de dados tradicionais, incorporando InteligÃªncia Artificial como parte do processo de extraÃ§Ã£o e enriquecimento de dados, refletindo cenÃ¡rios reais do mercado de dados.



